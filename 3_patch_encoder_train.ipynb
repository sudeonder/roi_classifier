{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c464961",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "3c464961"
      },
      "outputs": [],
      "source": [
        "# patch encoder training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/patches && rsync -ah --info=progress2 \"/content/drive/MyDrive/BRACS/ROIPatches/\" /content/patches/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnfNwSf-tEnA",
        "outputId": "583876d5-6550-47e3-e259-d06cfa210cb4"
      },
      "id": "mnfNwSf-tEnA",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          1.02G  88%  184.03kB/s    1:29:58 (xfr#8851, ir-chk=1063/10275)rsync error: received SIGINT, SIGTERM, or SIGHUP (code 20) at io.c(519) [generator=3.2.7]\n",
            "\n",
            "rsync error: received SIGINT, SIGTERM, or SIGHUP (code 20) at rsync.c(716) [sender=3.2.7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab: GPU + libs\n",
        "!nvidia-smi\n",
        "!pip -q install timm==0.9.16 torchmetrics==1.4.0\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")  # authenticate in the pop-up"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCvPAEMGwel0",
        "outputId": "31508258-0c0e-47ad-82d3-43ee32196026"
      },
      "id": "TCvPAEMGwel0",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 18 19:55:59 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0             52W /  400W |   33329MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, math, random, json, itertools, time\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import timm\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# === Paths (edit to your layout) ===\n",
        "#ROOT = Path(\"/content/drive/MyDrive/BRACS/ROIPatches\")\n",
        "ROOT = Path(\"/content/patches\")\n",
        "SPLITS_CSV = Path(\"/content/drive/MyDrive/BRACS/splits.csv\")   # patch_path,roi_id,split,label\n",
        "\n",
        "# === Classes (3-way) ===\n",
        "CLASSES = [\"B\", \"A\", \"M\"]  # Benign, Atypical, Malignant\n",
        "class_to_idx = {c:i for i,c in enumerate(CLASSES)}\n",
        "\n",
        "# === Training hyperparams per paper ===\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_PATCHES = 512           # fixed #patches per batch (not #ROIs)  :contentReference[oaicite:3]{index=3}\n",
        "MAX_PATCHES_PER_ROI = 30      # cap per-ROI to stabilize & regularize   :contentReference[oaicite:4]{index=4}\n",
        "EPOCHS = 40                   # paper uses 40 epochs × 500 batches      :contentReference[oaicite:5]{index=5}\n",
        "STEPS_PER_EPOCH = 180\n",
        "LR = 3e-2                     # SGD lr=0.03, momentum=0.75              :contentReference[oaicite:6]{index=6}\n",
        "MOMENTUM = 0.75\n",
        "WEIGHT_DECAY = 1e-4           # exclude BN/bias from WD                  :contentReference[oaicite:7]{index=7}\n",
        "DROP_RATE = 0.1               # dropout penultimate                       :contentReference[oaicite:8]{index=8}\n",
        "DROP_PATH_RATE = 0.25         # stochastic depth                          :contentReference[oaicite:9]{index=9}\n",
        "USE_AMP = True                # mixed precision                           :contentReference[oaicite:10]{index=10}\n",
        "\n",
        "# === Oversampling (class balancing) ===\n",
        "# In paper they oversample minority classes (Atypia ×3).\n",
        "# For 3-class (B,A,M), we oversample A (×3)\n",
        "OVERSAMPLE_MULT = {\"B\":1, \"A\":4, \"M\":1}\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ],
      "metadata": {
        "id": "D3lblvYZWS3Q"
      },
      "id": "D3lblvYZWS3Q",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# H&E-safe augmentations (axis flips + 90° rotations + light color jitter)\n",
        "def he_safe_train_transforms():\n",
        "    return T.Compose([\n",
        "        T.RandomResizedCrop(IMAGE_SIZE, scale=(0.8,1.0)),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.RandomVerticalFlip(),\n",
        "        # discrete 90° rotations (avoid free-angle; helps tissue realism)\n",
        "        T.Lambda(lambda x: T.functional.rotate(x, random.choice([0,90,180,270]))),\n",
        "        T.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.10, hue=0.02),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]), # ImageNet\n",
        "    ])\n",
        "\n",
        "def he_safe_eval_transforms():\n",
        "    return T.Compose([\n",
        "        T.Resize(256),\n",
        "        T.CenterCrop(IMAGE_SIZE),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    ])\n",
        "\n",
        "class PatchCSV(Dataset):\n",
        "    \"\"\"\n",
        "    Expects SPLITS_CSV with columns:\n",
        "      patch_path,roi_id,split,label\n",
        "    label ∈ {'B','A','M'}\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_path: Path, split: str, transform=None,\n",
        "                 max_per_roi: int = None, oversample_mult: dict = None):\n",
        "        import csv\n",
        "        self.transform = transform\n",
        "        rows = []\n",
        "        with open(csv_path, newline='') as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            for r in reader:\n",
        "                if r[\"split\"] != split: continue\n",
        "                lbl = r[\"label\"]\n",
        "                if lbl not in class_to_idx: continue\n",
        "                p = r[\"patch_path\"]\n",
        "                # ensure absolute path on Drive\n",
        "                if not p.startswith(\"/\"):\n",
        "                    p = str(ROOT/ p)\n",
        "                rows.append({\"path\": p, \"roi\": r[\"roi_id\"], \"y\": class_to_idx[lbl]})\n",
        "\n",
        "        # group by ROI\n",
        "        self.roi_to_indices = defaultdict(list)\n",
        "        self.samples = []\n",
        "        for i, row in enumerate(rows):\n",
        "            self.samples.append(row)\n",
        "            self.roi_to_indices[row[\"roi\"]].append(i)\n",
        "\n",
        "        # cap patches per ROI\n",
        "        if max_per_roi is not None:\n",
        "            kept = []\n",
        "            for roi, idxs in self.roi_to_indices.items():\n",
        "                if len(idxs) > max_per_roi:\n",
        "                    idxs = random.sample(idxs, max_per_roi)\n",
        "                kept += idxs\n",
        "            kept = set(kept)\n",
        "            self.samples = [self.samples[i] for i in range(len(self.samples)) if i in kept]\n",
        "\n",
        "        # oversample by class (for train only)\n",
        "        if oversample_mult is not None:\n",
        "            expanded = []\n",
        "            for s in self.samples:\n",
        "                cls = CLASSES[s[\"y\"]]\n",
        "                m = oversample_mult.get(cls, 1)\n",
        "                expanded += [s]*m\n",
        "            self.samples = expanded\n",
        "\n",
        "        # rebuild roi_to_indices after modifications\n",
        "        self.roi_to_indices = defaultdict(list)\n",
        "        for i, row in enumerate(self.samples):\n",
        "            self.roi_to_indices[row[\"roi\"]].append(i)\n",
        "\n",
        "        self.split = split\n",
        "        self.class_to_idx = class_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.samples[idx]\n",
        "        img = Image.open(row[\"path\"]).convert(\"RGB\")\n",
        "        if self.transform: img = self.transform(img)\n",
        "        y = row[\"y\"]\n",
        "        roi = row[\"roi\"]\n",
        "        return img, torch.tensor(y, dtype=torch.long), roi\n"
      ],
      "metadata": {
        "id": "NIB2RtrwWa2A"
      },
      "id": "NIB2RtrwWa2A",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedPatchBatchSampler(Sampler):\n",
        "    \"\"\"\n",
        "    Iterates over dataset indices to produce batches with exactly BATCH_PATCHES patches.\n",
        "    (We don't constrain #ROIs per batch, consistent with paper’s fixed patch count.) :contentReference[oaicite:12]{index=12}\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset: Dataset, steps_per_epoch: int, batch_patches: int):\n",
        "        self.N = len(dataset)\n",
        "        self.steps = steps_per_epoch\n",
        "        self.bs = batch_patches\n",
        "\n",
        "    def __iter__(self):\n",
        "        for _ in range(self.steps):\n",
        "            # uniform sample across all patches\n",
        "            idxs = np.random.randint(0, self.N, size=self.bs)\n",
        "            yield idxs.tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.steps\n"
      ],
      "metadata": {
        "id": "SNvo5F0oWfHs"
      },
      "id": "SNvo5F0oWfHs",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNetB0_3Way(nn.Module):\n",
        "    def __init__(self, drop_rate=0.1, drop_path_rate=0.25, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            \"efficientnet_b0\",\n",
        "            pretrained=pretrained,\n",
        "            num_classes=0,            # penultimate features\n",
        "            drop_rate=drop_rate,\n",
        "            drop_path_rate=drop_path_rate\n",
        "        )\n",
        "        in_feats = self.backbone.num_features  # 1280 for b0  :contentReference[oaicite:13]{index=13}\n",
        "        self.cls = nn.Linear(in_feats, len(CLASSES))\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)      # (B, 1280)\n",
        "        logits = self.cls(feats)      # (B, 3)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "nNyjUFOPWjJy"
      },
      "id": "nNyjUFOPWjJy",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.classification import MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
        "\n",
        "def make_metrics(num_classes=3):\n",
        "    prec = MulticlassPrecision(num_classes=num_classes, average=None).to(DEVICE)\n",
        "    rec  = MulticlassRecall(num_classes=num_classes, average=None).to(DEVICE)\n",
        "    f1   = MulticlassF1Score(num_classes=num_classes, average=None).to(DEVICE)\n",
        "    macro_prec = MulticlassPrecision(num_classes=num_classes, average=\"macro\").to(DEVICE)\n",
        "    macro_rec  = MulticlassRecall(num_classes=num_classes, average=\"macro\").to(DEVICE)\n",
        "    macro_f1   = MulticlassF1Score(num_classes=num_classes, average=\"macro\").to(DEVICE)\n",
        "    return dict(prec=prec, rec=rec, f1=f1, macro_prec=macro_prec, macro_rec=macro_rec, macro_f1=macro_f1)\n",
        "\n",
        "def gmean_from_recalls(rec_np):\n",
        "    # rec_np: (C,) with class recalls in [0,1]\n",
        "    rec_np = np.clip(rec_np, 1e-8, 1.0)\n",
        "    return float(np.exp(np.mean(np.log(rec_np))))  # geometric mean (paper’s main metric) :contentReference[oaicite:14]{index=14}\n"
      ],
      "metadata": {
        "id": "ity7GDLNXgkd"
      },
      "id": "ity7GDLNXgkd",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sanity_check_batch(dl):\n",
        "    xb, yb, rb = next(iter(dl))\n",
        "    assert xb.shape[-2:] == (IMAGE_SIZE, IMAGE_SIZE), \"Bad spatial size\"\n",
        "    assert xb.dtype == torch.float32\n",
        "    assert yb.dtype == torch.long and yb.ndim == 1\n",
        "    print(\"Batch ok:\", xb.shape, yb.shape, \"labels in\", yb.min().item(), yb.max().item())\n",
        "    print(\"Input mean/std:\", xb.mean().item(), xb.std().item())\n",
        "\n",
        "def tiny_overfit_test(model, dl, steps=200):\n",
        "    model.train()\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    scaler = GradScaler(enabled=False)\n",
        "    it = iter(dl)\n",
        "    for i in range(steps):\n",
        "        try: xb,yb,_ = next(it)\n",
        "        except StopIteration: it = iter(dl); xb,yb,_ = next(it)\n",
        "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        logits = model(xb)\n",
        "        loss = F.cross_entropy(logits, yb)\n",
        "        loss.backward(); opt.step()\n",
        "        if (i+1)%50==0:\n",
        "            with torch.no_grad():\n",
        "                acc = (logits.argmax(1)==yb).float().mean().item()\n",
        "            print(f\"[tiny overfit] step {i+1}: loss={loss.item():.4f}, acc={acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "gOAUdhStXhTC"
      },
      "id": "gOAUdhStXhTC",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with oversampling + cap per ROI; Val/Test without\n",
        "from torch.utils.data import SequentialSampler, BatchSampler\n",
        "train_ds = PatchCSV(SPLITS_CSV, \"train\", transform=he_safe_train_transforms(),\n",
        "                    max_per_roi=MAX_PATCHES_PER_ROI, oversample_mult=OVERSAMPLE_MULT)\n",
        "val_ds   = PatchCSV(SPLITS_CSV, \"val\",   transform=he_safe_eval_transforms(),\n",
        "                    max_per_roi=None, oversample_mult=None)\n",
        "test_ds  = PatchCSV(SPLITS_CSV, \"test\",  transform=he_safe_eval_transforms(),\n",
        "                    max_per_roi=None, oversample_mult=None)\n",
        "\n",
        "print(\"train/val/test sizes:\", len(train_ds), len(val_ds), len(test_ds))\n",
        "print(\"class_to_idx:\", train_ds.class_to_idx)\n",
        "\n",
        "# batch sampler for fixed #patches\n",
        "train_bsamp = FixedPatchBatchSampler(train_ds, STEPS_PER_EPOCH, BATCH_PATCHES)\n",
        "\n",
        "val_samp  = SequentialSampler(val_ds)  # visits every index exactly once, in order\n",
        "val_bsamp = BatchSampler(val_samp, batch_size=BATCH_PATCHES, drop_last=False)\n",
        "\n",
        "test_bsamp  = FixedPatchBatchSampler(test_ds,  steps_per_epoch=math.ceil(len(test_ds)/BATCH_PATCHES),\n",
        "                                     batch_patches=BATCH_PATCHES)\n",
        "\n",
        "def collate(items):\n",
        "    xs, ys, rs = zip(*items)\n",
        "    return torch.stack(xs,0), torch.tensor(ys), list(rs)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_sampler=train_bsamp, num_workers=4, pin_memory=True, collate_fn=collate)\n",
        "val_loader = DataLoader(val_ds,\n",
        "    batch_sampler=val_bsamp, num_workers=4, pin_memory=True, collate_fn=collate,\n",
        "    persistent_workers=True, prefetch_factor=4)\n",
        "test_loader  = DataLoader(test_ds,  batch_sampler=test_bsamp,  num_workers=4, pin_memory=True, collate_fn=collate)\n",
        "\n",
        "sanity_check_batch(train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8qrWi0vXj_9",
        "outputId": "88fb1779-2140-4af1-8d1b-3ef48c31ffcc"
      },
      "id": "T8qrWi0vXj_9",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/val/test sizes: 59427 9347 10744\n",
            "class_to_idx: {'B': 0, 'A': 1, 'M': 2}\n",
            "Batch ok: torch.Size([512, 3, 224, 224]) torch.Size([512]) labels in 0 2\n",
            "Input mean/std: 0.8429206013679504 0.9449635148048401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = EfficientNetB0_3Way(DROP_RATE, DROP_PATH_RATE, pretrained=True).to(DEVICE)\n",
        "\n",
        "# param groups: apply weight decay except BN/bias\n",
        "decay, no_decay = [], []\n",
        "for n,p in model.named_parameters():\n",
        "    if p.requires_grad:\n",
        "        if p.ndim == 1 or n.endswith(\".bias\") or \"bn\" in n.lower() or \"norm\" in n.lower():\n",
        "            no_decay.append(p)\n",
        "        else:\n",
        "            decay.append(p)\n",
        "optim = torch.optim.SGD(\n",
        "    [{\"params\": decay, \"weight_decay\": WEIGHT_DECAY},\n",
        "     {\"params\": no_decay, \"weight_decay\": 0.0}],\n",
        "    lr=LR, momentum=MOMENTUM, nesterov=False\n",
        ")\n",
        "scaler = GradScaler(enabled=USE_AMP)\n",
        "\n",
        "# quick optimizer sanity\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"params:\", num_params, \"trainable:\", num_trainable)\n",
        "for i,pg in enumerate(optim.param_groups):\n",
        "    print(f\"PG{i}: lr={pg['lr']} wd={pg['weight_decay']} #tensors={len(pg['params'])}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEnMwK9HaJ9e",
        "outputId": "5dd126ad-8b57-4125-f771-0643aae96e25"
      },
      "id": "XEnMwK9HaJ9e",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3681978343.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler(enabled=USE_AMP)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params: 4011391 trainable: 4011391\n",
            "PG0: lr=0.03 wd=0.0001 #tensors=82\n",
            "PG1: lr=0.03 wd=0.0 #tensors=131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def run_epoch(model, loader, train=True, epoch_idx=None):\n",
        "    mode = \"Train\" if train else \"Val\"\n",
        "    model.train() if train else model.eval()\n",
        "\n",
        "    metrics = make_metrics(num_classes=len(CLASSES))\n",
        "    total_loss, total = 0.0, 0\n",
        "    cls_counter = Counter()\n",
        "    start = time.time()\n",
        "\n",
        "    # ---- progress bar ----\n",
        "    pbar = tqdm(enumerate(loader), total=len(loader),\n",
        "                desc=f\"[{mode}] Epoch {epoch_idx if epoch_idx is not None else ''}\",\n",
        "                ncols=120)\n",
        "\n",
        "    for step, (xb, yb, _) in pbar:\n",
        "        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
        "        bs = xb.size(0)\n",
        "\n",
        "        # forward + loss\n",
        "        if train:\n",
        "            optim.zero_grad(set_to_none=True)\n",
        "            with autocast(enabled=USE_AMP):\n",
        "                logits = model(xb)\n",
        "                loss = F.cross_entropy(logits, yb)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optim)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                logits = model(xb)\n",
        "                loss = F.cross_entropy(logits, yb)\n",
        "\n",
        "        # metric + counters\n",
        "        with torch.no_grad():\n",
        "            preds = logits.argmax(1)\n",
        "            metrics[\"rec\"].update(preds, yb)\n",
        "            metrics[\"macro_rec\"].update(preds, yb)\n",
        "            for c, n in zip(*torch.unique(yb, return_counts=True)):\n",
        "                cls_counter[int(c.item())] += int(n.item())\n",
        "\n",
        "        total_loss += loss.item() * bs\n",
        "        total += bs\n",
        "\n",
        "        # ---- live logging ----\n",
        "        elapsed = time.time() - start\n",
        "        patches_per_s = total / max(elapsed, 1e-6)\n",
        "        est_total = len(loader)\n",
        "        remaining = (est_total - (step + 1)) * (elapsed / max(step + 1, 1))\n",
        "        msg = (f\"Step [{step+1:3d}/{len(loader)}] \"\n",
        "               f\"loss={loss.item():.4f} | patches/s={patches_per_s:.1f} \"\n",
        "               f\"| elapsed={elapsed/60:.1f}m | ETA={remaining/60:.1f}m\")\n",
        "        pbar.set_postfix_str(msg)\n",
        "\n",
        "    # ---- aggregate metrics ----\n",
        "    rec = metrics[\"rec\"].compute().detach().cpu().numpy()\n",
        "    macro_rec = float(metrics[\"macro_rec\"].compute().item())\n",
        "    gmean = gmean_from_recalls(rec)\n",
        "    avg_loss = total_loss / max(1, total)\n",
        "    elapsed = time.time() - start\n",
        "    counts = [cls_counter.get(i, 0) for i in range(len(CLASSES))]\n",
        "\n",
        "    print(f\"\\n[{mode}] Epoch done in {elapsed/60:.2f} min | \"\n",
        "          f\"avg_loss={avg_loss:.4f} | gmean={gmean:.4f} | \"\n",
        "          f\"recall(B,A,M)={np.round(rec,3)} | counts={counts}\")\n",
        "\n",
        "    return dict(loss=avg_loss, gmean=gmean, rec=rec, time=elapsed, seen_per_class=counts)\n",
        "\n",
        "\n",
        "# === Main training loop ===\n",
        "best = {\"gmean\": -1, \"state\": None, \"epoch\": -1}\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr = run_epoch(model, train_loader, train=True, epoch_idx=epoch)\n",
        "    va = run_epoch(model, val_loader, train=False, epoch_idx=epoch)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch:02d} | train_loss={tr['loss']:.4f} | \"\n",
        "          f\"val_gmean={va['gmean']:.4f} | \"\n",
        "          f\"recall(B,A,M)={np.round(va['rec'],3)} | \"\n",
        "          f\"time={tr['time']:.1f}s\")\n",
        "\n",
        "    # Save best and periodic checkpoints (every 5 epochs)\n",
        "if va[\"gmean\"] > best[\"gmean\"]:\n",
        "    best.update({\"gmean\": va[\"gmean\"], \"state\": model.state_dict(), \"epoch\": epoch})\n",
        "    ckpt_path = \"/content/drive/MyDrive/BRACS/checkpoints3/efficientnet_b0_3way_best.pt\"\n",
        "    os.makedirs(os.path.dirname(ckpt_path), exist_ok=True)\n",
        "    torch.save({\n",
        "        \"model\": best[\"state\"],\n",
        "        \"epoch\": epoch,\n",
        "        \"meta\": {\n",
        "            \"class_to_idx\": class_to_idx,\n",
        "            \"normalize_mean\": [0.485, 0.456, 0.406],\n",
        "            \"normalize_std\": [0.229, 0.224, 0.225],\n",
        "            \"image_size\": IMAGE_SIZE\n",
        "        }\n",
        "    }, ckpt_path)\n",
        "    print(f\"  ↳ saved best: {ckpt_path} (g-mean={best['gmean']:.4f})\")\n",
        "\n",
        "# Save periodic checkpoint every 5 epochs\n",
        "if epoch % 5 == 0:\n",
        "    ckpt_path = f\"/content/drive/MyDrive/BRACS/checkpoints3/efficientnet_b0_3way_epoch{epoch:03d}.pt\"\n",
        "    os.makedirs(os.path.dirname(ckpt_path), exist_ok=True)\n",
        "    torch.save({\n",
        "        \"model\": model.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"meta\": {\n",
        "            \"class_to_idx\": class_to_idx,\n",
        "            \"normalize_mean\": [0.485, 0.456, 0.406],\n",
        "            \"normalize_std\": [0.229, 0.224, 0.225],\n",
        "            \"image_size\": IMAGE_SIZE\n",
        "        }\n",
        "    }, ckpt_path)\n",
        "    print(f\"  ↳ saved periodic checkpoint: {ckpt_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0cG5Ik7HaX59",
        "outputId": "190fa298-1e60-4d26-f124-34c412d50776"
      },
      "id": "0cG5Ik7HaX59",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Train] Epoch 1:   0%|                                                                          | 0/180 [00:00<?, ?it/s]/tmp/ipython-input-592688770.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=USE_AMP):\n",
            "[Train] Epoch 1: 100%|█| 180/180 [05:39<00:00,  1.89s/it, Step [180/180] loss=0.2898 | patches/s=271.1 | elapsed=5.7m | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.67 min | avg_loss=0.4005 | gmean=0.8365 | recall(B,A,M)=[0.822 0.81  0.879] | counts=[30566, 26978, 34616]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 1: 100%|█| 19/19 [00:22<00:00,  1.20s/it, Step [ 19/19] loss=0.0173 | patches/s=408.6 | elapsed=0.4m | ETA=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.3096 | gmean=0.8100 | recall(B,A,M)=[0.872 0.662 0.921] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 01 | train_loss=0.4005 | val_gmean=0.8100 | recall(B,A,M)=[0.872 0.662 0.921] | time=340.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 2: 100%|█| 180/180 [05:35<00:00,  1.87s/it, Step [180/180] loss=0.1582 | patches/s=274.3 | elapsed=5.6m | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.60 min | avg_loss=0.2088 | gmean=0.9203 | recall(B,A,M)=[0.913 0.908 0.939] | counts=[30262, 27145, 34753]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 2: 100%|█| 19/19 [00:22<00:00,  1.18s/it, Step [ 19/19] loss=0.0117 | patches/s=418.4 | elapsed=0.4m | ETA=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.3148 | gmean=0.8033 | recall(B,A,M)=[0.889 0.63  0.925] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 02 | train_loss=0.2088 | val_gmean=0.8033 | recall(B,A,M)=[0.889 0.63  0.925] | time=336.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 3: 100%|█| 180/180 [05:33<00:00,  1.85s/it, Step [180/180] loss=0.1497 | patches/s=276.0 | elapsed=5.6m | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.57 min | avg_loss=0.1473 | gmean=0.9450 | recall(B,A,M)=[0.937 0.94  0.958] | counts=[30577, 26873, 34710]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 3: 100%|█| 19/19 [00:21<00:00,  1.16s/it, Step [ 19/19] loss=0.0065 | patches/s=425.8 | elapsed=0.4m | ETA=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.3983 | gmean=0.7705 | recall(B,A,M)=[0.873 0.578 0.906] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 03 | train_loss=0.1473 | val_gmean=0.7705 | recall(B,A,M)=[0.873 0.578 0.906] | time=334.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 4: 100%|█| 180/180 [05:31<00:00,  1.84s/it, Step [180/180] loss=0.0854 | patches/s=278.0 | elapsed=5.5m | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.53 min | avg_loss=0.1121 | gmean=0.9596 | recall(B,A,M)=[0.954 0.958 0.967] | counts=[30564, 26930, 34666]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 4: 100%|█| 19/19 [00:22<00:00,  1.18s/it, Step [ 19/19] loss=0.0017 | patches/s=416.3 | elapsed=0.4m | ETA=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.4867 | gmean=0.7351 | recall(B,A,M)=[0.882 0.508 0.887] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 04 | train_loss=0.1121 | val_gmean=0.7351 | recall(B,A,M)=[0.882 0.508 0.887] | time=331.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 5: 100%|█| 180/180 [05:33<00:00,  1.85s/it, Step [180/180] loss=0.0910 | patches/s=276.1 | elapsed=5.6m | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.56 min | avg_loss=0.0883 | gmean=0.9686 | recall(B,A,M)=[0.964 0.968 0.974] | counts=[30597, 27026, 34537]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 5: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0032 | patches/s=414.2 | elapsed=0.4m | ETA=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.4935 | gmean=0.7308 | recall(B,A,M)=[0.901 0.484 0.895] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 05 | train_loss=0.0883 | val_gmean=0.7308 | recall(B,A,M)=[0.901 0.484 0.895] | time=333.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 6: 100%|█| 180/180 [05:31<00:00,  1.84s/it, Step [180/180] loss=0.0710 | patches/s=277.8 | elapsed=5.5m | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.53 min | avg_loss=0.0716 | gmean=0.9739 | recall(B,A,M)=[0.97  0.973 0.978] | counts=[30437, 26992, 34731]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 6: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0056 | patches/s=411.8 | elapsed=0.4m | ETA=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.5528 | gmean=0.7359 | recall(B,A,M)=[0.886 0.509 0.885] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 06 | train_loss=0.0716 | val_gmean=0.7359 | recall(B,A,M)=[0.886 0.509 0.885] | time=331.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 7: 100%|█| 180/180 [05:29<00:00,  1.83s/it, Step [180/180] loss=0.0623 | patches/s=279.6 | elapsed=5.5m | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.50 min | avg_loss=0.0595 | gmean=0.9788 | recall(B,A,M)=[0.976 0.978 0.982] | counts=[30451, 27267, 34442]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 7: 100%|█| 19/19 [00:22<00:00,  1.17s/it, Step [ 19/19] loss=0.0016 | patches/s=418.9 | elapsed=0.4m | ETA=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.4865 | gmean=0.7182 | recall(B,A,M)=[0.884 0.446 0.94 ] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 07 | train_loss=0.0595 | val_gmean=0.7182 | recall(B,A,M)=[0.884 0.446 0.94 ] | time=329.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 8: 100%|█| 180/180 [05:29<00:00,  1.83s/it, Step [180/180] loss=0.0388 | patches/s=279.5 | elapsed=5.5m | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.50 min | avg_loss=0.0493 | gmean=0.9823 | recall(B,A,M)=[0.98  0.981 0.985] | counts=[30581, 26910, 34669]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 8: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0017 | patches/s=414.7 | elapsed=0.4m | ETA=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.5339 | gmean=0.7266 | recall(B,A,M)=[0.892 0.469 0.917] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 08 | train_loss=0.0493 | val_gmean=0.7266 | recall(B,A,M)=[0.892 0.469 0.917] | time=329.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 9: 100%|█| 180/180 [05:31<00:00,  1.84s/it, Step [180/180] loss=0.0348 | patches/s=278.2 | elapsed=5.5m | \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.52 min | avg_loss=0.0413 | gmean=0.9855 | recall(B,A,M)=[0.984 0.985 0.987] | counts=[30707, 27075, 34378]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 9: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0005 | patches/s=412.8 | elapsed=0.4m | ETA=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.6808 | gmean=0.6972 | recall(B,A,M)=[0.893 0.43  0.884] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 09 | train_loss=0.0413 | val_gmean=0.6972 | recall(B,A,M)=[0.893 0.43  0.884] | time=331.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 10: 100%|█| 180/180 [05:27<00:00,  1.82s/it, Step [180/180] loss=0.0378 | patches/s=281.6 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.46 min | avg_loss=0.0354 | gmean=0.9878 | recall(B,A,M)=[0.986 0.988 0.989] | counts=[30404, 27276, 34480]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 10: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0003 | patches/s=414.9 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.6554 | gmean=0.7015 | recall(B,A,M)=[0.899 0.427 0.898] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 10 | train_loss=0.0354 | val_gmean=0.7015 | recall(B,A,M)=[0.899 0.427 0.898] | time=327.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 11: 100%|█| 180/180 [05:30<00:00,  1.83s/it, Step [180/180] loss=0.0231 | patches/s=279.0 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.51 min | avg_loss=0.0313 | gmean=0.9896 | recall(B,A,M)=[0.989 0.989 0.991] | counts=[30444, 27063, 34653]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 11: 100%|█| 19/19 [00:22<00:00,  1.18s/it, Step [ 19/19] loss=0.0002 | patches/s=417.8 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.6153 | gmean=0.6996 | recall(B,A,M)=[0.899 0.413 0.922] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 11 | train_loss=0.0313 | val_gmean=0.6996 | recall(B,A,M)=[0.899 0.413 0.922] | time=330.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 12: 100%|█| 180/180 [05:33<00:00,  1.85s/it, Step [180/180] loss=0.0240 | patches/s=276.6 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.55 min | avg_loss=0.0295 | gmean=0.9896 | recall(B,A,M)=[0.989 0.989 0.991] | counts=[30448, 27190, 34522]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 12: 100%|█| 19/19 [00:22<00:00,  1.18s/it, Step [ 19/19] loss=0.0006 | patches/s=417.5 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.7362 | gmean=0.7027 | recall(B,A,M)=[0.906 0.436 0.878] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 12 | train_loss=0.0295 | val_gmean=0.7027 | recall(B,A,M)=[0.906 0.436 0.878] | time=333.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 13: 100%|█| 180/180 [05:35<00:00,  1.87s/it, Step [180/180] loss=0.0366 | patches/s=274.4 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.60 min | avg_loss=0.0260 | gmean=0.9911 | recall(B,A,M)=[0.99  0.991 0.993] | counts=[30824, 27113, 34223]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 13: 100%|█| 19/19 [00:22<00:00,  1.17s/it, Step [ 19/19] loss=0.0003 | patches/s=420.1 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.7122 | gmean=0.7004 | recall(B,A,M)=[0.889 0.43  0.9  ] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 13 | train_loss=0.0260 | val_gmean=0.7004 | recall(B,A,M)=[0.889 0.43  0.9  ] | time=336.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 14: 100%|█| 180/180 [05:36<00:00,  1.87s/it, Step [180/180] loss=0.0205 | patches/s=274.2 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.60 min | avg_loss=0.0226 | gmean=0.9923 | recall(B,A,M)=[0.991 0.993 0.993] | counts=[30370, 27132, 34658]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 14: 100%|█| 19/19 [00:22<00:00,  1.18s/it, Step [ 19/19] loss=0.0002 | patches/s=418.3 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.6495 | gmean=0.6956 | recall(B,A,M)=[0.891 0.409 0.924] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 14 | train_loss=0.0226 | val_gmean=0.6956 | recall(B,A,M)=[0.891 0.409 0.924] | time=336.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 15: 100%|█| 180/180 [05:34<00:00,  1.86s/it, Step [180/180] loss=0.0355 | patches/s=275.0 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.59 min | avg_loss=0.0206 | gmean=0.9931 | recall(B,A,M)=[0.992 0.993 0.994] | counts=[30549, 27028, 34583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 15: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0002 | patches/s=411.7 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.8128 | gmean=0.7033 | recall(B,A,M)=[0.9   0.438 0.882] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 15 | train_loss=0.0206 | val_gmean=0.7033 | recall(B,A,M)=[0.9   0.438 0.882] | time=335.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 16: 100%|█| 180/180 [05:29<00:00,  1.83s/it, Step [180/180] loss=0.0155 | patches/s=279.2 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.50 min | avg_loss=0.0176 | gmean=0.9941 | recall(B,A,M)=[0.994 0.994 0.995] | counts=[30327, 26930, 34903]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 16: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0001 | patches/s=412.8 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.7494 | gmean=0.6779 | recall(B,A,M)=[0.889 0.384 0.913] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 16 | train_loss=0.0176 | val_gmean=0.6779 | recall(B,A,M)=[0.889 0.384 0.913] | time=330.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 17: 100%|█| 180/180 [05:30<00:00,  1.83s/it, Step [180/180] loss=0.0118 | patches/s=279.2 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.50 min | avg_loss=0.0168 | gmean=0.9943 | recall(B,A,M)=[0.993 0.994 0.995] | counts=[30279, 27102, 34779]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 17: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0001 | patches/s=413.3 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.7129 | gmean=0.6892 | recall(B,A,M)=[0.897 0.395 0.924] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 17 | train_loss=0.0168 | val_gmean=0.6892 | recall(B,A,M)=[0.897 0.395 0.924] | time=330.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 18: 100%|█| 180/180 [05:34<00:00,  1.86s/it, Step [180/180] loss=0.0111 | patches/s=275.8 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.57 min | avg_loss=0.0163 | gmean=0.9943 | recall(B,A,M)=[0.994 0.994 0.995] | counts=[30373, 27153, 34634]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 18: 100%|█| 19/19 [00:22<00:00,  1.18s/it, Step [ 19/19] loss=0.0001 | patches/s=418.3 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.7166 | gmean=0.6765 | recall(B,A,M)=[0.887 0.38  0.919] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 18 | train_loss=0.0163 | val_gmean=0.6765 | recall(B,A,M)=[0.887 0.38  0.919] | time=334.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 19: 100%|█| 180/180 [05:32<00:00,  1.85s/it, Step [180/180] loss=0.0153 | patches/s=277.3 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.54 min | avg_loss=0.0138 | gmean=0.9953 | recall(B,A,M)=[0.995 0.995 0.996] | counts=[30451, 27243, 34466]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 19: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0001 | patches/s=413.3 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.7411 | gmean=0.6870 | recall(B,A,M)=[0.889 0.398 0.916] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 19 | train_loss=0.0138 | val_gmean=0.6870 | recall(B,A,M)=[0.889 0.398 0.916] | time=332.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 20: 100%|█| 180/180 [05:35<00:00,  1.86s/it, Step [180/180] loss=0.0056 | patches/s=274.8 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.59 min | avg_loss=0.0138 | gmean=0.9950 | recall(B,A,M)=[0.994 0.995 0.996] | counts=[30552, 27145, 34463]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 20: 100%|█| 19/19 [00:22<00:00,  1.18s/it, Step [ 19/19] loss=0.0002 | patches/s=416.4 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.8440 | gmean=0.6781 | recall(B,A,M)=[0.897 0.385 0.903] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 20 | train_loss=0.0138 | val_gmean=0.6781 | recall(B,A,M)=[0.897 0.385 0.903] | time=335.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 21: 100%|█| 180/180 [05:27<00:00,  1.82s/it, Step [180/180] loss=0.0101 | patches/s=281.8 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.45 min | avg_loss=0.0123 | gmean=0.9958 | recall(B,A,M)=[0.995 0.995 0.997] | counts=[30645, 26905, 34610]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 21: 100%|█| 19/19 [00:22<00:00,  1.17s/it, Step [ 19/19] loss=0.0001 | patches/s=421.5 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.7691 | gmean=0.7129 | recall(B,A,M)=[0.899 0.44  0.915] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 21 | train_loss=0.0123 | val_gmean=0.7129 | recall(B,A,M)=[0.899 0.44  0.915] | time=327.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 22: 100%|█| 180/180 [05:30<00:00,  1.84s/it, Step [180/180] loss=0.0034 | patches/s=278.4 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.52 min | avg_loss=0.0113 | gmean=0.9961 | recall(B,A,M)=[0.996 0.996 0.997] | counts=[30577, 26945, 34638]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 22: 100%|█| 19/19 [00:22<00:00,  1.18s/it, Step [ 19/19] loss=0.0001 | patches/s=416.3 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.8395 | gmean=0.6832 | recall(B,A,M)=[0.898 0.393 0.905] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 22 | train_loss=0.0113 | val_gmean=0.6832 | recall(B,A,M)=[0.898 0.393 0.905] | time=331.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 23: 100%|█| 180/180 [05:31<00:00,  1.84s/it, Step [180/180] loss=0.0147 | patches/s=278.3 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.52 min | avg_loss=0.0127 | gmean=0.9956 | recall(B,A,M)=[0.995 0.995 0.996] | counts=[30276, 27055, 34829]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 23: 100%|█| 19/19 [00:22<00:00,  1.18s/it, Step [ 19/19] loss=0.0002 | patches/s=418.5 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.7765 | gmean=0.6919 | recall(B,A,M)=[0.896 0.405 0.914] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 23 | train_loss=0.0127 | val_gmean=0.6919 | recall(B,A,M)=[0.896 0.405 0.914] | time=331.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 24: 100%|█| 180/180 [05:31<00:00,  1.84s/it, Step [180/180] loss=0.0082 | patches/s=277.7 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.53 min | avg_loss=0.0108 | gmean=0.9963 | recall(B,A,M)=[0.996 0.996 0.997] | counts=[30455, 27028, 34677]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 24: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0001 | patches/s=414.6 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.8632 | gmean=0.6772 | recall(B,A,M)=[0.886 0.387 0.905] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 24 | train_loss=0.0108 | val_gmean=0.6772 | recall(B,A,M)=[0.886 0.387 0.905] | time=332.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 25: 100%|█| 180/180 [05:34<00:00,  1.86s/it, Step [180/180] loss=0.0043 | patches/s=275.7 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.57 min | avg_loss=0.0104 | gmean=0.9964 | recall(B,A,M)=[0.996 0.996 0.997] | counts=[30530, 26879, 34751]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 25: 100%|█| 19/19 [00:22<00:00,  1.17s/it, Step [ 19/19] loss=0.0001 | patches/s=419.4 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.8293 | gmean=0.7002 | recall(B,A,M)=[0.889 0.424 0.911] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 25 | train_loss=0.0104 | val_gmean=0.7002 | recall(B,A,M)=[0.889 0.424 0.911] | time=334.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 26: 100%|█| 180/180 [05:34<00:00,  1.86s/it, Step [180/180] loss=0.0141 | patches/s=275.5 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.58 min | avg_loss=0.0091 | gmean=0.9969 | recall(B,A,M)=[0.997 0.997 0.997] | counts=[30682, 26957, 34521]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 26: 100%|█| 19/19 [00:22<00:00,  1.20s/it, Step [ 19/19] loss=0.0000 | patches/s=410.2 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.8224 | gmean=0.6685 | recall(B,A,M)=[0.887 0.37  0.911] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 26 | train_loss=0.0091 | val_gmean=0.6685 | recall(B,A,M)=[0.887 0.37  0.911] | time=334.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 27: 100%|█| 180/180 [05:33<00:00,  1.85s/it, Step [180/180] loss=0.0186 | patches/s=276.0 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.57 min | avg_loss=0.0081 | gmean=0.9974 | recall(B,A,M)=[0.997 0.997 0.998] | counts=[30516, 27090, 34554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 27: 100%|█| 19/19 [00:22<00:00,  1.17s/it, Step [ 19/19] loss=0.0001 | patches/s=420.1 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.8993 | gmean=0.6945 | recall(B,A,M)=[0.893 0.422 0.889] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 27 | train_loss=0.0081 | val_gmean=0.6945 | recall(B,A,M)=[0.893 0.422 0.889] | time=334.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 28: 100%|█| 180/180 [05:30<00:00,  1.84s/it, Step [180/180] loss=0.0055 | patches/s=278.8 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.51 min | avg_loss=0.0095 | gmean=0.9965 | recall(B,A,M)=[0.996 0.996 0.997] | counts=[30377, 27135, 34648]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 28: 100%|█| 19/19 [00:22<00:00,  1.18s/it, Step [ 19/19] loss=0.0000 | patches/s=416.9 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.8438 | gmean=0.6671 | recall(B,A,M)=[0.898 0.363 0.91 ] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 28 | train_loss=0.0095 | val_gmean=0.6671 | recall(B,A,M)=[0.898 0.363 0.91 ] | time=330.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 29: 100%|█| 180/180 [05:34<00:00,  1.86s/it, Step [180/180] loss=0.0052 | patches/s=275.2 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.58 min | avg_loss=0.0086 | gmean=0.9972 | recall(B,A,M)=[0.997 0.997 0.998] | counts=[30706, 26806, 34648]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 29: 100%|█| 19/19 [00:22<00:00,  1.20s/it, Step [ 19/19] loss=0.0001 | patches/s=410.9 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.7761 | gmean=0.7129 | recall(B,A,M)=[0.895 0.44  0.919] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 29 | train_loss=0.0086 | val_gmean=0.7129 | recall(B,A,M)=[0.895 0.44  0.919] | time=334.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 30: 100%|█| 180/180 [05:30<00:00,  1.84s/it, Step [180/180] loss=0.0100 | patches/s=278.4 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.52 min | avg_loss=0.0083 | gmean=0.9972 | recall(B,A,M)=[0.997 0.997 0.998] | counts=[30412, 27306, 34442]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 30: 100%|█| 19/19 [00:22<00:00,  1.20s/it, Step [ 19/19] loss=0.0000 | patches/s=411.4 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.6984 | gmean=0.7228 | recall(B,A,M)=[0.887 0.452 0.942] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 30 | train_loss=0.0083 | val_gmean=0.7228 | recall(B,A,M)=[0.887 0.452 0.942] | time=331.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 31: 100%|█| 180/180 [05:33<00:00,  1.85s/it, Step [180/180] loss=0.0041 | patches/s=276.1 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.56 min | avg_loss=0.0078 | gmean=0.9971 | recall(B,A,M)=[0.996 0.997 0.998] | counts=[30483, 27199, 34478]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 31: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0000 | patches/s=414.2 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.9164 | gmean=0.6553 | recall(B,A,M)=[0.908 0.342 0.907] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 31 | train_loss=0.0078 | val_gmean=0.6553 | recall(B,A,M)=[0.908 0.342 0.907] | time=333.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 32: 100%|█| 180/180 [05:34<00:00,  1.86s/it, Step [180/180] loss=0.0173 | patches/s=275.5 | elapsed=5.6m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.58 min | avg_loss=0.0072 | gmean=0.9976 | recall(B,A,M)=[0.997 0.997 0.998] | counts=[30654, 26917, 34589]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 32: 100%|█| 19/19 [00:22<00:00,  1.19s/it, Step [ 19/19] loss=0.0001 | patches/s=411.7 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.38 min | avg_loss=0.8171 | gmean=0.6933 | recall(B,A,M)=[0.896 0.405 0.92 ] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 32 | train_loss=0.0072 | val_gmean=0.6933 | recall(B,A,M)=[0.896 0.405 0.92 ] | time=334.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 33: 100%|█| 180/180 [05:28<00:00,  1.82s/it, Step [180/180] loss=0.0045 | patches/s=280.7 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.47 min | avg_loss=0.0070 | gmean=0.9975 | recall(B,A,M)=[0.997 0.997 0.998] | counts=[30286, 27058, 34816]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 33: 100%|█| 19/19 [00:22<00:00,  1.18s/it, Step [ 19/19] loss=0.0000 | patches/s=416.5 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.9050 | gmean=0.6841 | recall(B,A,M)=[0.898 0.393 0.908] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 33 | train_loss=0.0070 | val_gmean=0.6841 | recall(B,A,M)=[0.898 0.393 0.908] | time=328.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 34: 100%|█| 180/180 [05:27<00:00,  1.82s/it, Step [180/180] loss=0.0165 | patches/s=281.4 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.46 min | avg_loss=0.0064 | gmean=0.9977 | recall(B,A,M)=[0.998 0.997 0.998] | counts=[30514, 27009, 34637]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 34: 100%|█| 19/19 [00:22<00:00,  1.17s/it, Step [ 19/19] loss=0.0000 | patches/s=420.0 | elapsed=0.4m | ETA=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Epoch done in 0.37 min | avg_loss=0.8502 | gmean=0.6939 | recall(B,A,M)=[0.9   0.407 0.913] | counts=[1897, 922, 6528]\n",
            "\n",
            "Epoch 34 | train_loss=0.0064 | val_gmean=0.6939 | recall(B,A,M)=[0.9   0.407 0.913] | time=327.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train] Epoch 35: 100%|█| 180/180 [05:30<00:00,  1.83s/it, Step [180/180] loss=0.0143 | patches/s=279.1 | elapsed=5.5m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 5.50 min | avg_loss=0.0064 | gmean=0.9978 | recall(B,A,M)=[0.997 0.998 0.998] | counts=[30556, 26945, 34659]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 35:  84%|▊| 16/19 [00:19<00:02,  1.44it/s, Step [ 16/19] loss=0.2730 | patches/s=429.8 | elapsed=0.3m | ETA=Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a3ebe94e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a3ebe94e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a3ebe94e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6a3ebe94e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "[Val] Epoch 35:  84%|▊| 16/19 [00:21<00:04,  1.35s/it, Step [ 16/19] loss=0.2730 | patches/s=429.8 | elapsed=0.3m | ETA=\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "DataLoader worker (pid(s) 175968) exited unexpectedly",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 175968) is killed by signal: Aborted. ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-592688770.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mva\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     print(f\"\\nEpoch {epoch:02d} | train_loss={tr['loss']:.4f} | \"\n",
            "\u001b[0;32m/tmp/ipython-input-592688770.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, loader, train, epoch_idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 ncols=120)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m   1299\u001b[0m                     \u001b[0;34mf\"DataLoader worker (pid(s) {pids_str}) exited unexpectedly\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                 ) from e\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 175968) exited unexpectedly"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qBYpogIFA0NT"
      },
      "id": "qBYpogIFA0NT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}