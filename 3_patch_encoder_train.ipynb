{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c464961",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "3c464961"
      },
      "outputs": [],
      "source": [
        "# patch encoder training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/patches && rsync -ah --info=progress2 \"/content/drive/MyDrive/BRACS/ROIPatches/\" /content/patches/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnfNwSf-tEnA",
        "outputId": "583876d5-6550-47e3-e259-d06cfa210cb4"
      },
      "id": "mnfNwSf-tEnA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        619.26M  80%  180.68kB/s    0:55:46 (xfr#5464, ir-chk=1264/7089)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab: GPU + libs\n",
        "!nvidia-smi\n",
        "!pip -q install timm==0.9.16 torchmetrics==1.4.0\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")  # authenticate in the pop-up"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCvPAEMGwel0",
        "outputId": "2eeab8d0-fab8-490d-a4fd-94128efbf8cf"
      },
      "id": "TCvPAEMGwel0",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 18 12:30:33 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0             47W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, math, random, json, itertools, time\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import timm\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# === Paths (edit to your layout) ===\n",
        "#ROOT = Path(\"/content/drive/MyDrive/BRACS/ROIPatches\")\n",
        "ROOT = Path(\"/content/patches\")\n",
        "SPLITS_CSV = Path(\"/content/drive/MyDrive/BRACS/splits.csv\")   # patch_path,roi_id,split,label\n",
        "\n",
        "# === Classes (3-way) ===\n",
        "CLASSES = [\"B\", \"A\", \"M\"]  # Benign, Atypical, Malignant\n",
        "class_to_idx = {c:i for i,c in enumerate(CLASSES)}\n",
        "\n",
        "# === Training hyperparams per paper ===\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_PATCHES = 512           # fixed #patches per batch (not #ROIs)  :contentReference[oaicite:3]{index=3}\n",
        "MAX_PATCHES_PER_ROI = 30      # cap per-ROI to stabilize & regularize   :contentReference[oaicite:4]{index=4}\n",
        "EPOCHS = 40                   # paper uses 40 epochs × 500 batches      :contentReference[oaicite:5]{index=5}\n",
        "STEPS_PER_EPOCH = 20\n",
        "LR = 3e-2                     # SGD lr=0.03, momentum=0.75              :contentReference[oaicite:6]{index=6}\n",
        "MOMENTUM = 0.75\n",
        "WEIGHT_DECAY = 1e-4           # exclude BN/bias from WD                  :contentReference[oaicite:7]{index=7}\n",
        "DROP_RATE = 0.1               # dropout penultimate                       :contentReference[oaicite:8]{index=8}\n",
        "DROP_PATH_RATE = 0.25         # stochastic depth                          :contentReference[oaicite:9]{index=9}\n",
        "USE_AMP = True                # mixed precision                           :contentReference[oaicite:10]{index=10}\n",
        "\n",
        "# === Oversampling (class balancing) ===\n",
        "# In paper they oversample minority classes (Atypia ×3).\n",
        "# For 3-class (B,A,M), we oversample A (×3)\n",
        "OVERSAMPLE_MULT = {\"B\":1, \"A\":3, \"M\":1}\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ],
      "metadata": {
        "id": "D3lblvYZWS3Q"
      },
      "id": "D3lblvYZWS3Q",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# H&E-safe augmentations (axis flips + 90° rotations + light color jitter)\n",
        "def he_safe_train_transforms():\n",
        "    return T.Compose([\n",
        "        T.RandomResizedCrop(IMAGE_SIZE, scale=(0.8,1.0)),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.RandomVerticalFlip(),\n",
        "        # discrete 90° rotations (avoid free-angle; helps tissue realism)\n",
        "        T.Lambda(lambda x: T.functional.rotate(x, random.choice([0,90,180,270]))),\n",
        "        T.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.10, hue=0.02),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]), # ImageNet\n",
        "    ])\n",
        "\n",
        "def he_safe_eval_transforms():\n",
        "    return T.Compose([\n",
        "        T.Resize(256),\n",
        "        T.CenterCrop(IMAGE_SIZE),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    ])\n",
        "\n",
        "class PatchCSV(Dataset):\n",
        "    \"\"\"\n",
        "    Expects SPLITS_CSV with columns:\n",
        "      patch_path,roi_id,split,label\n",
        "    label ∈ {'B','A','M'}\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_path: Path, split: str, transform=None,\n",
        "                 max_per_roi: int = None, oversample_mult: dict = None):\n",
        "        import csv\n",
        "        self.transform = transform\n",
        "        rows = []\n",
        "        with open(csv_path, newline='') as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            for r in reader:\n",
        "                if r[\"split\"] != split: continue\n",
        "                lbl = r[\"label\"]\n",
        "                if lbl not in class_to_idx: continue\n",
        "                p = r[\"patch_path\"]\n",
        "                # ensure absolute path on Drive\n",
        "                if not p.startswith(\"/\"):\n",
        "                    p = str(ROOT/ p)\n",
        "                rows.append({\"path\": p, \"roi\": r[\"roi_id\"], \"y\": class_to_idx[lbl]})\n",
        "\n",
        "        # group by ROI\n",
        "        self.roi_to_indices = defaultdict(list)\n",
        "        self.samples = []\n",
        "        for i, row in enumerate(rows):\n",
        "            self.samples.append(row)\n",
        "            self.roi_to_indices[row[\"roi\"]].append(i)\n",
        "\n",
        "        # cap patches per ROI\n",
        "        if max_per_roi is not None:\n",
        "            kept = []\n",
        "            for roi, idxs in self.roi_to_indices.items():\n",
        "                if len(idxs) > max_per_roi:\n",
        "                    idxs = random.sample(idxs, max_per_roi)\n",
        "                kept += idxs\n",
        "            kept = set(kept)\n",
        "            self.samples = [self.samples[i] for i in range(len(self.samples)) if i in kept]\n",
        "\n",
        "        # oversample by class (for train only)\n",
        "        if oversample_mult is not None:\n",
        "            expanded = []\n",
        "            for s in self.samples:\n",
        "                cls = CLASSES[s[\"y\"]]\n",
        "                m = oversample_mult.get(cls, 1)\n",
        "                expanded += [s]*m\n",
        "            self.samples = expanded\n",
        "\n",
        "        # rebuild roi_to_indices after modifications\n",
        "        self.roi_to_indices = defaultdict(list)\n",
        "        for i, row in enumerate(self.samples):\n",
        "            self.roi_to_indices[row[\"roi\"]].append(i)\n",
        "\n",
        "        self.split = split\n",
        "        self.class_to_idx = class_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.samples[idx]\n",
        "        img = Image.open(row[\"path\"]).convert(\"RGB\")\n",
        "        if self.transform: img = self.transform(img)\n",
        "        y = row[\"y\"]\n",
        "        roi = row[\"roi\"]\n",
        "        return img, torch.tensor(y, dtype=torch.long), roi\n"
      ],
      "metadata": {
        "id": "NIB2RtrwWa2A"
      },
      "id": "NIB2RtrwWa2A",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedPatchBatchSampler(Sampler):\n",
        "    \"\"\"\n",
        "    Iterates over dataset indices to produce batches with exactly BATCH_PATCHES patches.\n",
        "    (We don't constrain #ROIs per batch, consistent with paper’s fixed patch count.) :contentReference[oaicite:12]{index=12}\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset: Dataset, steps_per_epoch: int, batch_patches: int):\n",
        "        self.N = len(dataset)\n",
        "        self.steps = steps_per_epoch\n",
        "        self.bs = batch_patches\n",
        "\n",
        "    def __iter__(self):\n",
        "        for _ in range(self.steps):\n",
        "            # uniform sample across all patches\n",
        "            idxs = np.random.randint(0, self.N, size=self.bs)\n",
        "            yield idxs.tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.steps\n"
      ],
      "metadata": {
        "id": "SNvo5F0oWfHs"
      },
      "id": "SNvo5F0oWfHs",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNetB0_3Way(nn.Module):\n",
        "    def __init__(self, drop_rate=0.1, drop_path_rate=0.25, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            \"efficientnet_b0\",\n",
        "            pretrained=pretrained,\n",
        "            num_classes=0,            # penultimate features\n",
        "            drop_rate=drop_rate,\n",
        "            drop_path_rate=drop_path_rate\n",
        "        )\n",
        "        in_feats = self.backbone.num_features  # 1280 for b0  :contentReference[oaicite:13]{index=13}\n",
        "        self.cls = nn.Linear(in_feats, len(CLASSES))\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)      # (B, 1280)\n",
        "        logits = self.cls(feats)      # (B, 3)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "nNyjUFOPWjJy"
      },
      "id": "nNyjUFOPWjJy",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.classification import MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
        "\n",
        "def make_metrics(num_classes=3):\n",
        "    prec = MulticlassPrecision(num_classes=num_classes, average=None).to(DEVICE)\n",
        "    rec  = MulticlassRecall(num_classes=num_classes, average=None).to(DEVICE)\n",
        "    f1   = MulticlassF1Score(num_classes=num_classes, average=None).to(DEVICE)\n",
        "    macro_prec = MulticlassPrecision(num_classes=num_classes, average=\"macro\").to(DEVICE)\n",
        "    macro_rec  = MulticlassRecall(num_classes=num_classes, average=\"macro\").to(DEVICE)\n",
        "    macro_f1   = MulticlassF1Score(num_classes=num_classes, average=\"macro\").to(DEVICE)\n",
        "    return dict(prec=prec, rec=rec, f1=f1, macro_prec=macro_prec, macro_rec=macro_rec, macro_f1=macro_f1)\n",
        "\n",
        "def gmean_from_recalls(rec_np):\n",
        "    # rec_np: (C,) with class recalls in [0,1]\n",
        "    rec_np = np.clip(rec_np, 1e-8, 1.0)\n",
        "    return float(np.exp(np.mean(np.log(rec_np))))  # geometric mean (paper’s main metric) :contentReference[oaicite:14]{index=14}\n"
      ],
      "metadata": {
        "id": "ity7GDLNXgkd"
      },
      "id": "ity7GDLNXgkd",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sanity_check_batch(dl):\n",
        "    xb, yb, rb = next(iter(dl))\n",
        "    assert xb.shape[-2:] == (IMAGE_SIZE, IMAGE_SIZE), \"Bad spatial size\"\n",
        "    assert xb.dtype == torch.float32\n",
        "    assert yb.dtype == torch.long and yb.ndim == 1\n",
        "    print(\"Batch ok:\", xb.shape, yb.shape, \"labels in\", yb.min().item(), yb.max().item())\n",
        "    print(\"Input mean/std:\", xb.mean().item(), xb.std().item())\n",
        "\n",
        "def tiny_overfit_test(model, dl, steps=200):\n",
        "    model.train()\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    scaler = GradScaler(enabled=False)\n",
        "    it = iter(dl)\n",
        "    for i in range(steps):\n",
        "        try: xb,yb,_ = next(it)\n",
        "        except StopIteration: it = iter(dl); xb,yb,_ = next(it)\n",
        "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        logits = model(xb)\n",
        "        loss = F.cross_entropy(logits, yb)\n",
        "        loss.backward(); opt.step()\n",
        "        if (i+1)%50==0:\n",
        "            with torch.no_grad():\n",
        "                acc = (logits.argmax(1)==yb).float().mean().item()\n",
        "            print(f\"[tiny overfit] step {i+1}: loss={loss.item():.4f}, acc={acc:.3f}\")\n"
      ],
      "metadata": {
        "id": "gOAUdhStXhTC"
      },
      "id": "gOAUdhStXhTC",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with oversampling + cap per ROI; Val/Test without\n",
        "train_ds = PatchCSV(SPLITS_CSV, \"train\", transform=he_safe_train_transforms(),\n",
        "                    max_per_roi=MAX_PATCHES_PER_ROI, oversample_mult=OVERSAMPLE_MULT)\n",
        "val_ds   = PatchCSV(SPLITS_CSV, \"val\",   transform=he_safe_eval_transforms(),\n",
        "                    max_per_roi=None, oversample_mult=None)\n",
        "test_ds  = PatchCSV(SPLITS_CSV, \"test\",  transform=he_safe_eval_transforms(),\n",
        "                    max_per_roi=None, oversample_mult=None)\n",
        "\n",
        "print(\"train/val/test sizes:\", len(train_ds), len(val_ds), len(test_ds))\n",
        "print(\"class_to_idx:\", train_ds.class_to_idx)\n",
        "\n",
        "# batch sampler for fixed #patches\n",
        "train_bsamp = FixedPatchBatchSampler(train_ds, STEPS_PER_EPOCH, BATCH_PATCHES)\n",
        "val_bsamp   = FixedPatchBatchSampler(val_ds,   steps_per_epoch=math.ceil(len(val_ds)/BATCH_PATCHES),\n",
        "                                     batch_patches=BATCH_PATCHES)\n",
        "test_bsamp  = FixedPatchBatchSampler(test_ds,  steps_per_epoch=math.ceil(len(test_ds)/BATCH_PATCHES),\n",
        "                                     batch_patches=BATCH_PATCHES)\n",
        "\n",
        "def collate(items):\n",
        "    xs, ys, rs = zip(*items)\n",
        "    return torch.stack(xs,0), torch.tensor(ys), list(rs)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_sampler=train_bsamp, num_workers=4, pin_memory=True, collate_fn=collate)\n",
        "val_loader   = DataLoader(val_ds,   batch_sampler=val_bsamp,   num_workers=4, pin_memory=True, collate_fn=collate)\n",
        "test_loader  = DataLoader(test_ds,  batch_sampler=test_bsamp,  num_workers=4, pin_memory=True, collate_fn=collate)\n",
        "\n",
        "sanity_check_batch(train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8qrWi0vXj_9",
        "outputId": "d2a6c420-525b-4259-8232-8cc93a45a42a"
      },
      "id": "T8qrWi0vXj_9",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/val/test sizes: 46365 9347 10744\n",
            "class_to_idx: {'B': 0, 'A': 1, 'M': 2}\n",
            "Batch ok: torch.Size([512, 3, 224, 224]) torch.Size([512]) labels in 0 2\n",
            "Input mean/std: 0.8646245002746582 0.9363856315612793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = EfficientNetB0_3Way(DROP_RATE, DROP_PATH_RATE, pretrained=True).to(DEVICE)\n",
        "\n",
        "# param groups: apply weight decay except BN/bias\n",
        "decay, no_decay = [], []\n",
        "for n,p in model.named_parameters():\n",
        "    if p.requires_grad:\n",
        "        if p.ndim == 1 or n.endswith(\".bias\") or \"bn\" in n.lower() or \"norm\" in n.lower():\n",
        "            no_decay.append(p)\n",
        "        else:\n",
        "            decay.append(p)\n",
        "optim = torch.optim.SGD(\n",
        "    [{\"params\": decay, \"weight_decay\": WEIGHT_DECAY},\n",
        "     {\"params\": no_decay, \"weight_decay\": 0.0}],\n",
        "    lr=LR, momentum=MOMENTUM, nesterov=False\n",
        ")\n",
        "scaler = GradScaler(enabled=USE_AMP)\n",
        "\n",
        "# quick optimizer sanity\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"params:\", num_params, \"trainable:\", num_trainable)\n",
        "for i,pg in enumerate(optim.param_groups):\n",
        "    print(f\"PG{i}: lr={pg['lr']} wd={pg['weight_decay']} #tensors={len(pg['params'])}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEnMwK9HaJ9e",
        "outputId": "ebe2c105-73ad-443a-e992-b13af72f10e4"
      },
      "id": "XEnMwK9HaJ9e",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3681978343.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler(enabled=USE_AMP)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params: 4011391 trainable: 4011391\n",
            "PG0: lr=0.03 wd=0.0001 #tensors=82\n",
            "PG1: lr=0.03 wd=0.0 #tensors=131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def run_epoch(model, loader, train=True, epoch_idx=None):\n",
        "    mode = \"Train\" if train else \"Val\"\n",
        "    model.train() if train else model.eval()\n",
        "\n",
        "    metrics = make_metrics(num_classes=len(CLASSES))\n",
        "    total_loss, total = 0.0, 0\n",
        "    cls_counter = Counter()\n",
        "    start = time.time()\n",
        "\n",
        "    # ---- progress bar ----\n",
        "    pbar = tqdm(enumerate(loader), total=len(loader),\n",
        "                desc=f\"[{mode}] Epoch {epoch_idx if epoch_idx is not None else ''}\",\n",
        "                ncols=120)\n",
        "\n",
        "    for step, (xb, yb, _) in pbar:\n",
        "        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
        "        bs = xb.size(0)\n",
        "\n",
        "        # forward + loss\n",
        "        if train:\n",
        "            optim.zero_grad(set_to_none=True)\n",
        "            with autocast(enabled=USE_AMP):\n",
        "                logits = model(xb)\n",
        "                loss = F.cross_entropy(logits, yb)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optim)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                logits = model(xb)\n",
        "                loss = F.cross_entropy(logits, yb)\n",
        "\n",
        "        # metric + counters\n",
        "        with torch.no_grad():\n",
        "            preds = logits.argmax(1)\n",
        "            metrics[\"rec\"].update(preds, yb)\n",
        "            metrics[\"macro_rec\"].update(preds, yb)\n",
        "            for c, n in zip(*torch.unique(yb, return_counts=True)):\n",
        "                cls_counter[int(c.item())] += int(n.item())\n",
        "\n",
        "        total_loss += loss.item() * bs\n",
        "        total += bs\n",
        "\n",
        "        # ---- live logging ----\n",
        "        elapsed = time.time() - start\n",
        "        patches_per_s = total / max(elapsed, 1e-6)\n",
        "        est_total = len(loader)\n",
        "        remaining = (est_total - (step + 1)) * (elapsed / max(step + 1, 1))\n",
        "        msg = (f\"Step [{step+1:3d}/{len(loader)}] \"\n",
        "               f\"loss={loss.item():.4f} | patches/s={patches_per_s:.1f} \"\n",
        "               f\"| elapsed={elapsed/60:.1f}m | ETA={remaining/60:.1f}m\")\n",
        "        pbar.set_postfix_str(msg)\n",
        "\n",
        "    # ---- aggregate metrics ----\n",
        "    rec = metrics[\"rec\"].compute().detach().cpu().numpy()\n",
        "    macro_rec = float(metrics[\"macro_rec\"].compute().item())\n",
        "    gmean = gmean_from_recalls(rec)\n",
        "    avg_loss = total_loss / max(1, total)\n",
        "    elapsed = time.time() - start\n",
        "    counts = [cls_counter.get(i, 0) for i in range(len(CLASSES))]\n",
        "\n",
        "    print(f\"\\n[{mode}] Epoch done in {elapsed/60:.2f} min | \"\n",
        "          f\"avg_loss={avg_loss:.4f} | gmean={gmean:.4f} | \"\n",
        "          f\"recall(B,A,M)={np.round(rec,3)} | counts={counts}\")\n",
        "\n",
        "    return dict(loss=avg_loss, gmean=gmean, rec=rec, time=elapsed, seen_per_class=counts)\n",
        "\n",
        "\n",
        "# === Main training loop ===\n",
        "best = {\"gmean\": -1, \"state\": None, \"epoch\": -1}\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr = run_epoch(model, train_loader, train=True, epoch_idx=epoch)\n",
        "    va = run_epoch(model, val_loader, train=False, epoch_idx=epoch)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch:02d} | train_loss={tr['loss']:.4f} | \"\n",
        "          f\"val_gmean={va['gmean']:.4f} | \"\n",
        "          f\"recall(B,A,M)={np.round(va['rec'],3)} | \"\n",
        "          f\"time={tr['time']:.1f}s\")\n",
        "\n",
        "    if va[\"gmean\"] > best[\"gmean\"]:\n",
        "        best.update({\"gmean\": va[\"gmean\"], \"state\": model.state_dict(), \"epoch\": epoch})\n",
        "        ckpt_path = \"/content/drive/MyDrive/BRACS/checkpoints/efficientnet_b0_3way_best.pt\"\n",
        "        os.makedirs(os.path.dirname(ckpt_path), exist_ok=True)\n",
        "        torch.save({\n",
        "            \"model\": best[\"state\"],\n",
        "            \"epoch\": epoch,\n",
        "            \"meta\": {\n",
        "                \"class_to_idx\": class_to_idx,\n",
        "                \"normalize_mean\": [0.485,0.456,0.406],\n",
        "                \"normalize_std\":  [0.229,0.224,0.225],\n",
        "                \"image_size\": IMAGE_SIZE\n",
        "            }\n",
        "        }, ckpt_path)\n",
        "        print(f\"  ↳ saved best: {ckpt_path} (g-mean={best['gmean']:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "0cG5Ik7HaX59",
        "outputId": "a9982148-e224-4877-d084-0b52d10e898e"
      },
      "id": "0cG5Ik7HaX59",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Train] Epoch 1:   0%|                                                                           | 0/20 [00:00<?, ?it/s]/tmp/ipython-input-2977260495.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=USE_AMP):\n",
            "[Train] Epoch 1: 100%|█| 20/20 [16:55<00:00, 50.76s/it, Step [ 20/20] loss=0.4286 | patches/s=10.1 | elapsed=16.9m | ETA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train] Epoch done in 16.93 min | avg_loss=0.4980 | gmean=0.4994 | recall(B,A,M)=[0.849 0.164 0.894] | counts=[4297, 945, 4998]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Val] Epoch 1:   0%|                                                                             | 0/19 [03:14<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2977260495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mva\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     print(f\"\\nEpoch {epoch:02d} | train_loss={tr['loss']:.4f} | \"\n",
            "\u001b[0;32m/tmp/ipython-input-2977260495.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, loader, train, epoch_idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 ncols=120)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}