{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f58b84f3",
      "metadata": {
        "id": "f58b84f3"
      },
      "source": [
        "# roi patching pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gcsfs fsspec tqdm pillow opencv-python\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # Accept the prompt\n",
        "\n",
        "import os, json, io, csv, re, math\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import fsspec\n",
        "from tqdm import tqdm\n",
        "import cv2"
      ],
      "metadata": {
        "id": "L8OvLRdRRlKQ"
      },
      "id": "L8OvLRdRRlKQ",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install in Colab if not present\n",
        "!pip -q install google-cloud-storage pillow tqdm\n",
        "\n",
        "import os, io, json, csv, time, shutil, glob, threading, gc\n",
        "from pathlib import Path\n",
        "from multiprocessing import Queue, Event, Process, Manager\n",
        "from google.cloud import storage\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive as gdrive\n",
        "\n",
        "# === Mount Google Drive ===\n",
        "MOUNT_POINT = \"/content/drive\"\n",
        "gdrive.mount(MOUNT_POINT, force_remount=True)\n",
        "\n",
        "# === Config ===\n",
        "BUCKET_NAME = \"bracs-dataset-bucket\"\n",
        "ROOT_PREFIX = \"BRACS/BRACS_RoI/latest_version\"\n",
        "SPLITS = [\"train\",\"val\",\"test\"]\n",
        "LESIONS = [\"0_N\",\"1_PB\",\"2_UDH\",\"3_FEA\",\"4_ADH\",\"5_DCIS\",\"6_IC\"]\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/BRACS/ROIPatches\")\n",
        "DRIVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "PATCH_SIZE = 224\n",
        "STRIDE = 74\n",
        "GPU_DEVICE = \"cuda:0\"\n",
        "NUM_PRODUCERS = 6\n",
        "NUM_SAVER_THREADS = 4\n",
        "SAVE_BATCH = 256\n",
        "DOWNSCALE_FACTOR = 4   # 40x -> 10x\n",
        "\n",
        "# image safety guard\n",
        "Image.MAX_IMAGE_PIXELS = 300_000_000\n",
        "\n",
        "# === GCS ===\n",
        "client = storage.Client()\n",
        "bucket = client.bucket(BUCKET_NAME)\n",
        "\n",
        "def parse_ids(blob_name: str):\n",
        "    p = Path(blob_name)\n",
        "    return p.parent.parent.name, p.parent.name, p.stem  # split, lesion, roi_id\n",
        "\n",
        "def list_blob_names(split, lesion):\n",
        "    prefix = f\"{ROOT_PREFIX}/{split}/{lesion}/\"\n",
        "    for b in client.list_blobs(BUCKET_NAME, prefix=prefix):\n",
        "        if b.name.lower().endswith(\".png\") and Path(b.name).parent.name == lesion:\n",
        "            yield b.name\n",
        "\n",
        "def fetch_blob_bytes(blob_name, retries=4):\n",
        "    b = bucket.blob(blob_name); backoff = 1.0\n",
        "    for k in range(retries):\n",
        "        try:\n",
        "            return blob_name, b.download_as_bytes()\n",
        "        except Exception as e:\n",
        "            if k == retries-1: raise\n",
        "            time.sleep(backoff); backoff *= 1.7\n",
        "\n",
        "def decode_image_bytes(img_bytes):\n",
        "    return np.array(Image.open(io.BytesIO(img_bytes)).convert(\"RGB\"))\n",
        "\n",
        "def downscale_to_10x(img_np: np.ndarray, factor: int = DOWNSCALE_FACTOR) -> np.ndarray:\n",
        "    \"\"\"Area-like downscale: fast & good for reducing resolution.\"\"\"\n",
        "    h, w = img_np.shape[:2]\n",
        "    nh, nw = max(1, h // factor), max(1, w // factor)\n",
        "    im = Image.fromarray(img_np)\n",
        "    # BOX is efficient for downscaling; LANCZOS is also fine but heavier\n",
        "    return np.array(im.resize((nw, nh), resample=Image.BOX))\n",
        "\n",
        "# === Producer ===\n",
        "def producer_worker(work_queue: Queue, blob_names, stop_event: Event):\n",
        "    for blob_name in blob_names:\n",
        "        if stop_event.is_set(): break\n",
        "        try:\n",
        "            _, bts = fetch_blob_bytes(blob_name)\n",
        "            work_queue.put((blob_name, bts))\n",
        "        except Exception as e:\n",
        "            print(f\"[PRODUCER][ERR] {blob_name} -> {e}\")\n",
        "\n",
        "# === GPU consumer ===\n",
        "def gpu_consumer(work_q: Queue, save_q: Queue, stop_evt: Event, stats=None):\n",
        "    device = torch.device(GPU_DEVICE); torch.cuda.set_device(device)\n",
        "    ks, st = PATCH_SIZE, STRIDE\n",
        "\n",
        "    while not (stop_evt.is_set() and work_q.empty()):\n",
        "        try:\n",
        "            blob_name, bts = work_q.get(timeout=2)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        split, lesion, roi_id = parse_ids(blob_name)\n",
        "\n",
        "        # decode @40x\n",
        "        try:\n",
        "            img_np_40 = decode_image_bytes(bts)\n",
        "        except Exception as e:\n",
        "            if stats: stats[\"done\"] += 1\n",
        "            continue\n",
        "\n",
        "        # ---- NEW: downscale to 10x (factor 4) ----\n",
        "        img_np = downscale_to_10x(img_np_40, DOWNSCALE_FACTOR)\n",
        "        del img_np_40, bts  # free immediately\n",
        "        gc.collect()\n",
        "\n",
        "        H, W, _ = img_np.shape\n",
        "        if H < ks or W < ks:\n",
        "            if stats:\n",
        "                stats[\"done\"] += 1\n",
        "                if stats[\"done\"] % 10 == 0 or stats[\"done\"] == stats[\"total\"]:\n",
        "                    print(f\"[PROGRESS] {stats['done']}/{stats['total']}\")\n",
        "            del img_np; gc.collect()\n",
        "            continue\n",
        "\n",
        "        # to GPU\n",
        "        img_t = torch.from_numpy(img_np).permute(2,0,1).unsqueeze(0).to(device=device, dtype=torch.float32) / 255.0\n",
        "        del img_np; gc.collect()\n",
        "\n",
        "        # unfold patches\n",
        "        unf = F.unfold(img_t, kernel_size=ks, stride=st)   # 1 x (3*ks*ks) x L\n",
        "        L = unf.shape[-1]\n",
        "        if L == 0:\n",
        "            if stats:\n",
        "                stats[\"done\"] += 1\n",
        "                if stats[\"done\"] % 10 == 0 or stats[\"done\"] == stats[\"total\"]:\n",
        "                    print(f\"[PROGRESS] {stats['done']}/{stats['total']}\")\n",
        "            del img_t, unf; torch.cuda.empty_cache()\n",
        "            continue\n",
        "\n",
        "        patches = unf.squeeze(0).transpose(0,1).reshape(L,3,ks,ks).contiguous()\n",
        "        brightness = patches.mean(dim=(1,2,3))\n",
        "        sat        = patches.std(dim=(1,2,3))\n",
        "        keep       = (brightness < 0.85) & (sat > 0.02)\n",
        "        keep_idx   = torch.nonzero(keep).squeeze(1)\n",
        "        if keep_idx.numel() == 0:\n",
        "            if stats:\n",
        "                stats[\"done\"] += 1\n",
        "                if stats[\"done\"] % 10 == 0 or stats[\"done\"] == stats[\"total\"]:\n",
        "                    print(f\"[PROGRESS] {stats['done']}/{stats['total']}\")\n",
        "            del img_t, unf, patches, brightness, sat, keep, keep_idx\n",
        "            torch.cuda.empty_cache()\n",
        "            continue\n",
        "\n",
        "        kept = patches[keep_idx]\n",
        "        cols = (W - ks)//st + 1\n",
        "        ys_all = (torch.arange(L, device=device) // cols) * st\n",
        "        xs_all = (torch.arange(L, device=device) %  cols) * st\n",
        "        ys = ys_all[keep_idx].cpu().numpy().tolist()\n",
        "        xs = xs_all[keep_idx].cpu().numpy().tolist()\n",
        "\n",
        "        # enqueue for saving (to Drive mount)\n",
        "        batch, K = [], kept.shape[0]\n",
        "        for i in range(K):\n",
        "            patch_np = (kept[i].permute(1,2,0).cpu().numpy() * 255.0).astype(\"uint8\")\n",
        "            y, x = ys[i], xs[i]\n",
        "            batch.append((blob_name, x, y, patch_np))\n",
        "            if len(batch) >= SAVE_BATCH:\n",
        "                save_q.put(batch); batch = []\n",
        "        if batch:\n",
        "            save_q.put(batch)\n",
        "\n",
        "        # concise progress\n",
        "        if stats:\n",
        "            stats[\"done\"] += 1\n",
        "            if stats[\"done\"] % 10 == 0 or stats[\"done\"] == stats[\"total\"]:\n",
        "                print(f\"[PROGRESS] {stats['done']}/{stats['total']}\")\n",
        "\n",
        "        # cleanup GPU/CPU memory (no local ROI files are kept)\n",
        "        del img_t, unf, patches, brightness, sat, keep, keep_idx, kept\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "# === Saver (writes directly to mounted Drive) ===\n",
        "def saver_thread(save_q: Queue, stop_evt: Event):\n",
        "    while not (stop_evt.is_set() and save_q.empty()):\n",
        "        try:\n",
        "            batch = save_q.get(timeout=2)\n",
        "        except Exception:\n",
        "            continue\n",
        "        for blob_name, x, y, patch_np in batch:\n",
        "            split, lesion, roi = parse_ids(blob_name)\n",
        "            out_dir = (DRIVE_ROOT / split / lesion / roi)\n",
        "            out_dir.mkdir(parents=True, exist_ok=True)\n",
        "            out_path = out_dir / f\"patch_y{y}_x{x}.png\"\n",
        "            Image.fromarray(patch_np).save(out_path, format=\"PNG\")\n",
        "        # hint kernel to flush page cache\n",
        "        try: os.sync()\n",
        "        except: pass\n",
        "\n",
        "# === Orchestration ===\n",
        "if __name__ == \"__main__\":\n",
        "    mgr = Manager()\n",
        "    work_q = mgr.Queue(maxsize=NUM_PRODUCERS * 4)\n",
        "    save_q = mgr.Queue(maxsize=NUM_SAVER_THREADS * 8)\n",
        "    stop_evt = Event()\n",
        "\n",
        "    # gather ROIs\n",
        "    all_blob_names = []\n",
        "    for split in SPLITS:\n",
        "        for lesion in LESIONS:\n",
        "            all_blob_names.extend(list(list_blob_names(split, lesion)))\n",
        "    total_rois = len(all_blob_names)\n",
        "    print(\"Total ROIs:\", total_rois)\n",
        "\n",
        "    # stats for concise progress\n",
        "    stats = mgr.dict(total=total_rois, done=0)\n",
        "\n",
        "    # start producers\n",
        "    producers = []\n",
        "    chunk = max(1, total_rois // max(1, NUM_PRODUCERS))\n",
        "    for i in range(NUM_PRODUCERS):\n",
        "        s = i*chunk\n",
        "        e = None if i == NUM_PRODUCERS-1 else (i+1)*chunk\n",
        "        p = Process(target=producer_worker, args=(work_q, all_blob_names[s:e], stop_evt))\n",
        "        p.start(); producers.append(p)\n",
        "\n",
        "    # consumer\n",
        "    gpu_p = Process(target=gpu_consumer, args=(work_q, save_q, stop_evt, stats))\n",
        "    gpu_p.start()\n",
        "\n",
        "    # savers\n",
        "    savers = []\n",
        "    for i in range(NUM_SAVER_THREADS):\n",
        "        t = threading.Thread(target=saver_thread, args=(save_q, stop_evt), daemon=True)\n",
        "        t.start(); savers.append(t)\n",
        "\n",
        "    # wait\n",
        "    for p in producers: p.join()\n",
        "    stop_evt.set()\n",
        "    gpu_p.join()\n",
        "\n",
        "    while not save_q.empty():\n",
        "        time.sleep(1)\n",
        "\n",
        "    # final cleanup (no ROI files were stored; free memory)\n",
        "    gc.collect()\n",
        "    print(\"[MAIN] Done.\")\n"
      ],
      "metadata": {
        "id": "mx0LkMiajCpL"
      },
      "id": "mx0LkMiajCpL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}