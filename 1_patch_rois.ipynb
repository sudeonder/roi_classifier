{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f58b84f3",
      "metadata": {
        "id": "f58b84f3"
      },
      "source": [
        "# roi patching pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gcsfs fsspec tqdm pillow opencv-python\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # Accept the prompt\n",
        "\n",
        "import os, json, io, csv, re, math\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import fsspec\n",
        "from tqdm import tqdm\n",
        "import cv2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8OvLRdRRlKQ",
        "outputId": "87ca73cf-5f9e-4f87-ce4f-781a83e11bcf"
      },
      "id": "L8OvLRdRRlKQ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install in Colab if not present\n",
        "!pip -q install google-cloud-storage pillow tqdm\n",
        "\n",
        "import os, io, json, csv, time\n",
        "from pathlib import Path\n",
        "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
        "from multiprocessing import Queue, Event, Process\n",
        "from google.cloud import storage\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# === Config ===\n",
        "BUCKET_NAME = \"bracs-dataset-bucket\"\n",
        "ROOT_PREFIX = \"BRACS/BRACS_RoI/latest_version\"\n",
        "SPLITS = [\"train\",\"val\",\"test\"]\n",
        "LESIONS = [\"0_N\",\"1_PB\",\"2_UDH\",\"3_FEA\",\"4_ADH\",\"5_DCIS\",\"6_IC\"]\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/BRACS/ROIPatches\")\n",
        "DRIVE_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "PATCH_SIZE = 224\n",
        "STRIDE = 74\n",
        "MIN_PATCHES = 5\n",
        "BATCH_MAX_PATCHES = 4096  # max patches to process per GPU step (tune to GPU mem)\n",
        "GPU_DEVICE = \"cuda:0\"     # change if using another GPU idx\n",
        "NUM_PRODUCERS = 6         # number of parallel fetchers (tune with CPU & network)\n",
        "NUM_SAVER_THREADS = 4     # threads writing images to Drive\n",
        "\n",
        "# PIL image size guard: increase for big ROIs (see note)\n",
        "from PIL import Image\n",
        "Image.MAX_IMAGE_PIXELS = 300_000_000\n",
        "\n",
        "# === Helpers ===\n",
        "client = storage.Client()\n",
        "bucket = client.bucket(BUCKET_NAME)\n",
        "\n",
        "# --- Helper: parse split / lesion / roi_id from blob path ---\n",
        "def parse_ids(blob_name: str):\n",
        "    parts = Path(blob_name).parts\n",
        "    # .../BRACS/BRACS_RoI/latest_version/{split}/{lesion}/{roi}.png\n",
        "    lesion = parts[-2]\n",
        "    split  = parts[-3]\n",
        "    roi_id = Path(blob_name).stem\n",
        "    return split, lesion, roi_id\n",
        "\n",
        "\n",
        "# --- Add near the top (helper) ---\n",
        "def roi_already_processed(blob_name: str) -> bool:\n",
        "    \"\"\"\n",
        "    Check if this ROI already exists in Drive output.\n",
        "    We consider an ROI processed if its folder exists and contains any patch files.\n",
        "    \"\"\"\n",
        "    parts = Path(blob_name).parts\n",
        "    try:\n",
        "        lesion = parts[-2]\n",
        "        split = parts[-3]\n",
        "        roi_id = Path(blob_name).stem\n",
        "    except IndexError:\n",
        "        return False\n",
        "    roi_dir = DRIVE_ROOT / split / lesion / roi_id\n",
        "    if roi_dir.exists():\n",
        "        # Check for at least one patch image file\n",
        "        patch_files = list(roi_dir.glob(\"patch_*.png\"))\n",
        "        if len(patch_files) > 0:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "# --- Updated process_one_blob (used by GPU consumer or CPU version) ---\n",
        "def process_one_blob(blob_name: str, bts: bytes):\n",
        "    \"\"\"\n",
        "    Processes one ROI blob (downloaded bytes already available).\n",
        "    Skips if ROI already processed in Drive.\n",
        "    \"\"\"\n",
        "    # --- Check for already processed ROI ---\n",
        "    if roi_already_processed(blob_name):\n",
        "        print(f\"[SKIP] {blob_name} (already processed)\")\n",
        "        return 0, \"skipped_existing\"\n",
        "\n",
        "    # Decode image\n",
        "    try:\n",
        "        img = decode_image_bytes(bts)\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed to decode {blob_name}: {e}\")\n",
        "        return 0, \"decode_error\"\n",
        "\n",
        "    # --- Your existing tiling and patch saving logic ---\n",
        "    # (GPU vectorized version or CPU version goes here)\n",
        "    # e.g., pass img_np to tile_roi or GPU unfold etc.\n",
        "    # At the end, return (num_patches, status)\n",
        "\n",
        "    # Example dummy return to show structure:\n",
        "    return len([]), \"ok\"  # replace with actual logic\n",
        "\n",
        "\n",
        "def list_blob_names(split, lesion):\n",
        "    prefix = f\"{ROOT_PREFIX}/{split}/{lesion}/\"\n",
        "    blobs = client.list_blobs(BUCKET_NAME, prefix=prefix)\n",
        "    for b in blobs:\n",
        "        if b.name.lower().endswith(\".png\") and Path(b.name).parent.name == lesion:\n",
        "            yield b.name\n",
        "\n",
        "def fetch_blob_bytes(blob_name):\n",
        "    b = bucket.blob(blob_name)\n",
        "    return blob_name, b.download_as_bytes()\n",
        "\n",
        "# quick CPU decode that we use in producer (small overhead)\n",
        "def decode_image_bytes(img_bytes):\n",
        "    return np.array(Image.open(io.BytesIO(img_bytes)).convert(\"RGB\"))\n",
        "\n",
        "# create output dir\n",
        "def save_patch_cpu(out_path: Path, patch_np: np.ndarray):\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    Image.fromarray(patch_np).save(out_path, format=\"PNG\")\n",
        "\n",
        "# === Producer function (runs in separate processes) ===\n",
        "def producer_worker(work_queue: Queue, blob_names_iterable, stop_event: Event):\n",
        "    # fetch blobs and put into queue as (blob_name, bytes)\n",
        "    for blob_name in blob_names_iterable:\n",
        "        if stop_event.is_set():\n",
        "            break\n",
        "        try:\n",
        "            # download bytes (fast, single call)\n",
        "            blob = bucket.blob(blob_name)\n",
        "            bts = blob.download_as_bytes()\n",
        "            work_queue.put((blob_name, bts))\n",
        "        except Exception as e:\n",
        "            print(\"Producer error\", blob_name, e)\n",
        "    # producer done\n",
        "    return\n",
        "\n",
        "# === GPU consumer (single process) ===\n",
        "def gpu_consumer(work_queue: Queue, save_queue: Queue, stop_event: Event):\n",
        "    device = torch.device(GPU_DEVICE)\n",
        "    torch.cuda.set_device(device)\n",
        "\n",
        "    # knobs\n",
        "    ks = PATCH_SIZE\n",
        "    st = STRIDE\n",
        "    MAX_L_PER_BLOCK = 40_000   # max number of patches handled per block (tune)\n",
        "    SAVE_CHUNK = 256           # how many patches to enqueue per save batch\n",
        "\n",
        "    while not (stop_event.is_set() and work_queue.empty()):\n",
        "        try:\n",
        "            blob_name, bts = work_queue.get(timeout=2)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        # skip if already processed\n",
        "        if roi_already_processed(blob_name):\n",
        "            print(f\"[SKIP] {blob_name} (already processed)\")\n",
        "            continue\n",
        "\n",
        "        split, lesion, roi_id = parse_ids(blob_name)\n",
        "        print(f\"[PATCH] start {split}/{lesion}/{roi_id}\")\n",
        "\n",
        "        # ---- decode on CPU\n",
        "        try:\n",
        "            img_np = decode_image_bytes(bts)  # H x W x 3, uint8\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Decode failed {blob_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "        H, W, _ = img_np.shape\n",
        "        if H < ks or W < ks:\n",
        "            print(f\"[SKIP] {split}/{lesion}/{roi_id} (too small: {H}x{W})\")\n",
        "            continue\n",
        "\n",
        "        # ---- to GPU (FP16)\n",
        "        img_t = (torch.from_numpy(img_np)\n",
        "                 .permute(2,0,1)              # 3xHxW\n",
        "                 .unsqueeze(0)                # 1x3xHxW\n",
        "                 .to(device=device, dtype=torch.float16)) / 255.0\n",
        "\n",
        "        # number of starting positions along rows/cols\n",
        "        n_rows = (H - ks)//st + 1\n",
        "        n_cols = (W - ks)//st + 1\n",
        "        if n_rows <= 0 or n_cols <= 0:\n",
        "            print(f\"[SKIP] {split}/{lesion}/{roi_id} (no full patches)\")\n",
        "            del img_t; torch.cuda.empty_cache()\n",
        "            continue\n",
        "\n",
        "        # choose rows per block so rows_per_block * n_cols <= MAX_L_PER_BLOCK\n",
        "        rows_per_block = max(1, min(n_rows, MAX_L_PER_BLOCK // max(1, n_cols)))\n",
        "        # band height we need to slice: (rows_per_block-1)*st + ks\n",
        "        band_h = (rows_per_block - 1)*st + ks\n",
        "\n",
        "        total_kept = 0\n",
        "        # process vertical bands\n",
        "        for row_start in range(0, n_rows, rows_per_block):\n",
        "            # compute the y-range in pixels we need\n",
        "            y0 = row_start * st\n",
        "            y1 = y0 + band_h\n",
        "            if y1 > H:\n",
        "                # last band: clamp to image bottom, recompute rows_this\n",
        "                y1 = H\n",
        "                # recompute rows_this from actual band height\n",
        "                rows_this = ( (y1 - y0) - ks ) // st + 1\n",
        "            else:\n",
        "                rows_this = rows_per_block\n",
        "\n",
        "            # crop band (still on GPU)\n",
        "            band = img_t[:, :, y0:y1, :]  # 1x3x(band_h)xW\n",
        "\n",
        "            # unfold on the band\n",
        "            # L_band = rows_this * n_cols\n",
        "            patches_unf = F.unfold(band, kernel_size=ks, stride=st)  # 1 x (3*ks*ks) x L_band\n",
        "            L_band = patches_unf.shape[-1]\n",
        "            if L_band == 0:\n",
        "                del patches_unf, band\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "\n",
        "            # compute brightness & “sat” cheaply without full reshape\n",
        "            # mean over patch dimension (dim=1 is flattened 3*ks*ks)\n",
        "            brightness = patches_unf.mean(dim=1)                             # [L_band]\n",
        "            # approximate saturation via std over flattened channels/pixels\n",
        "            sat = patches_unf.std(dim=1)                                     # [L_band]\n",
        "\n",
        "            keep_mask = (brightness < 0.85) & (sat > 0.02)\n",
        "            keep_idxs = torch.nonzero(keep_mask, as_tuple=False).squeeze(1)  # [K]\n",
        "            if keep_idxs.numel() == 0:\n",
        "                del patches_unf, band, brightness, sat, keep_mask\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "\n",
        "            # We will stream patches in chunks to avoid big gathers\n",
        "            # Compute coordinates for all L_band patches in this band\n",
        "            cols_idx = torch.arange(L_band, device=device) % n_cols\n",
        "            rows_idx = torch.arange(L_band, device=device) // n_cols\n",
        "            xs_all = cols_idx * st\n",
        "            ys_all = rows_idx * st + y0  # offset by band start in pixels\n",
        "\n",
        "            xs_keep = xs_all[keep_idxs].to(\"cpu\", non_blocking=True).tolist()\n",
        "            ys_keep = ys_all[keep_idxs].to(\"cpu\", non_blocking=True).tolist()\n",
        "\n",
        "            # stream save in chunks: gather a small slice of columns from patches_unf\n",
        "            # We need actual 3xksxks patches to write PNGs:\n",
        "            # For chunked gather, take indices slice and reshape only that slice.\n",
        "            K = keep_idxs.numel()\n",
        "            start = 0\n",
        "            while start < K:\n",
        "                end = min(start + SAVE_CHUNK, K)\n",
        "                idx_slice = keep_idxs[start:end]\n",
        "\n",
        "                # gather subset: (1, C*ks*ks, m)\n",
        "                sub_unf = patches_unf.index_select(dim=2, index=idx_slice)\n",
        "                # reshape to (m, 3, ks, ks)\n",
        "                sub = sub_unf.squeeze(0).transpose(0,1).reshape(-1, 3, ks, ks).contiguous()\n",
        "\n",
        "                # to CPU uint8\n",
        "                sub_cpu = (sub.permute(0,2,3,1).to(dtype=torch.float32) * 255.0).to(\"cpu\", non_blocking=True).numpy().astype(\"uint8\")\n",
        "\n",
        "                # coords for this slice\n",
        "                xs_slice = xs_keep[start:end]\n",
        "                ys_slice = ys_keep[start:end]\n",
        "\n",
        "                # enqueue save batch\n",
        "                batch = []\n",
        "                for i in range(len(xs_slice)):\n",
        "                    batch.append((blob_name, xs_slice[i], ys_slice[i], sub_cpu[i]))\n",
        "                save_queue.put(batch)\n",
        "\n",
        "                total_kept += len(xs_slice)\n",
        "\n",
        "                # free slice tensors\n",
        "                del sub_unf, sub, sub_cpu\n",
        "                start = end\n",
        "                # optional: tiny sync helps fragmentation on some drivers\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "            # free band tensors\n",
        "            del patches_unf, band, brightness, sat, keep_mask, keep_idxs\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"[PATCH] extracted {total_kept} patches for {split}/{lesion}/{roi_id} -> enqueued\")\n",
        "\n",
        "        # free big image tensor\n",
        "        del img_t\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "# === Saver: runs in ThreadPool (multiple threads) to write PNGs to Drive ===\n",
        "def saver_thread(save_queue: Queue, stop_event: Event):\n",
        "    while not (stop_event.is_set() and save_queue.empty()):\n",
        "        try:\n",
        "            batch = save_queue.get(timeout=2)  # batch = list of (blob_name, x, y, patch_np)\n",
        "        except Exception:\n",
        "            continue\n",
        "        for blob_name, x, y, patch_np in batch:\n",
        "            # compute split/lesion/roi id from blob_name like ROOT_PREFIX/{split}/{lesion}/BRACS_123.png\n",
        "            parts = Path(blob_name).parts\n",
        "            # parts[-3] = lesion, parts[-4] = split in the given layout\n",
        "            lesion = parts[-2]\n",
        "            split = parts[-3]\n",
        "            roi_fname = Path(blob_name).stem\n",
        "            out_dir = DRIVE_ROOT / split / lesion / roi_fname\n",
        "            out_dir.mkdir(parents=True, exist_ok=True)\n",
        "            out_path = out_dir / f\"patch_y{y}_x{x}.png\"\n",
        "            Image.fromarray(patch_np).save(out_path, format=\"PNG\")\n",
        "        # optionally flush, write manifest etc.\n",
        "\n",
        "# === Orchestration ===\n",
        "if __name__ == \"__main__\":\n",
        "    from multiprocessing import Manager\n",
        "    mgr = Manager()\n",
        "    work_q = mgr.Queue(maxsize=NUM_PRODUCERS * 4)\n",
        "    save_q = mgr.Queue(maxsize=NUM_SAVER_THREADS * 8)\n",
        "    stop_evt = mgr.Event()\n",
        "\n",
        "    # prepare lists of blob names\n",
        "    all_blob_names = []\n",
        "    for split in SPLITS:\n",
        "        for lesion in LESIONS:\n",
        "            all_blob_names.extend(list(list_blob_names(split, lesion)))\n",
        "    print(\"Total ROIs:\", len(all_blob_names))\n",
        "\n",
        "    # start producers as Processes\n",
        "    producers = []\n",
        "    chunk_size = max(1, len(all_blob_names) // NUM_PRODUCERS)\n",
        "    for i in range(NUM_PRODUCERS):\n",
        "        start = i * chunk_size\n",
        "        end = None if i == NUM_PRODUCERS - 1 else (i+1) * chunk_size\n",
        "        p_blob_names = all_blob_names[start:end]\n",
        "        p = Process(target=producer_worker, args=(work_q, p_blob_names, stop_evt))\n",
        "        p.start()\n",
        "        producers.append(p)\n",
        "\n",
        "    # start GPU consumer\n",
        "    gpu_proc = Process(target=gpu_consumer, args=(work_q, save_q, stop_evt))\n",
        "    gpu_proc.start()\n",
        "\n",
        "    # start saver threads\n",
        "    import threading\n",
        "    savers = []\n",
        "    for i in range(NUM_SAVER_THREADS):\n",
        "        t = threading.Thread(target=saver_thread, args=(save_q, stop_evt), daemon=True)\n",
        "        t.start()\n",
        "        savers.append(t)\n",
        "\n",
        "    # wait for producers to finish\n",
        "    for p in producers:\n",
        "        p.join()\n",
        "\n",
        "    # producers done: set stop event and wait for queues to drain\n",
        "    stop_evt.set()\n",
        "    gpu_proc.join(timeout=600)\n",
        "    # wait until save_q empty\n",
        "    while not save_q.empty():\n",
        "        time.sleep(1)\n",
        "    print(\"All done.\")\n"
      ],
      "metadata": {
        "id": "mx0LkMiajCpL",
        "outputId": "086c114f-08b0-4188-8a9e-38e6569a408b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "mx0LkMiajCpL",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total ROIs: 4539\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1642_PB_3.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1903_ADH_8.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1003675_N_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1506_FEA_11.png (already processed)Producer error\n",
            " BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_752_DCIS_38.png Checksum mismatch while downloading:\n",
            "\n",
            "  https://storage.googleapis.com/download/storage/v1/b/bracs-dataset-bucket/o/BRACS%2FBRACS_RoI%2Flatest_version%2Ftrain%2F5_DCIS%2FBRACS_752_DCIS_38.png?alt=media\n",
            "\n",
            "The X-Goog-Hash header indicated an MD5 checksum of:\n",
            "\n",
            "  TN/TDfQ4Z8Z8giiXRDmJog==\n",
            "\n",
            "but the actual MD5 checksum of the downloaded contents was:\n",
            "\n",
            "  FqDALFhwtyRqZdBPQL6gDg==\n",
            "\n",
            "The X-Goog-Stored-Content-Length is 11230062. The X-Goog-Stored-Content-Encoding is identity.\n",
            "\n",
            "The download request read 11230062 bytes of data.\n",
            "If the download was incomplete, please check the network connection and restart the download.\n",
            "\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_739_UDH_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1642_PB_4.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1903_ADH_9.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1003713_N_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1509_FEA_10.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_752_DCIS_4.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_739_UDH_10.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1642_PB_5.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1911_ADH_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1509_FEA_17.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_752_DCIS_40.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1003714_N_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_739_UDH_16.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1642_PB_6.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1911_ADH_2.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1509_FEA_21.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_739_UDH_22.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1003715_N_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1911_ADH_3.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1642_PB_7.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_752_DCIS_41.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1003716_N_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1911_ADH_4.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_739_UDH_27.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_10.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_752_DCIS_42.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1003717_N_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1911_ADH_5.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_739_UDH_33.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_11.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_752_DCIS_43.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1667_PB_4.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1003718_N_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_740_UDH_11.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_15.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1911_ADH_6.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_740_UDH_16.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_16.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_752_DCIS_5.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_11.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1911_ADH_7.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_740_UDH_18.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_18.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_18.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1912_ADH_3.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_752_DCIS_6.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_740_UDH_20.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1667_PB_6.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_19.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_19.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1912_ADH_4.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1771_PB_56.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_752_DCIS_9.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_740_UDH_21.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_20.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_24.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_753_DCIS_10.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/2_UDH/BRACS_740_UDH_5.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1912_ADH_5.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1772_PB_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_22.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_27.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_753_DCIS_11.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1912_ADH_7.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_23.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/3_FEA/BRACS_1271_FEA_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1772_PB_2.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_29.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_3.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/3_FEA/BRACS_1271_FEA_10.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1912_ADH_8.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_753_DCIS_12.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/3_FEA/BRACS_1271_FEA_14.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_4.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1913_ADH_4.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_37.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1772_PB_3.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_753_DCIS_13.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_6.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1915_ADH_4.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/3_FEA/BRACS_1271_FEA_15.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_38.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_7.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1772_PB_4.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1920_ADH_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_39.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/3_FEA/BRACS_1271_FEA_16.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_753_DCIS_14.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1510_FEA_9.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1920_ADH_6.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_40.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1772_PB_5.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/3_FEA/BRACS_1271_FEA_6.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1920_ADH_7.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1771_FEA_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_753_DCIS_15.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/3_FEA/BRACS_1610_FEA_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_41.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1772_PB_6.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1771_FEA_10.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1921_ADH_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1771_FEA_100.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/3_FEA/BRACS_1610_FEA_10.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_45.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1772_PB_7.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1921_ADH_4.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1771_FEA_101.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_50.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_753_DCIS_17.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1773_PB_13.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/3_FEA/BRACS_1797_FEA_1.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1771_FEA_11.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_52.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_753_DCIS_2.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1773_PB_4.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1771_FEA_12.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1922_ADH_2.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/val/3_FEA/BRACS_1797_FEA_2.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_54.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1773_PB_5.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/3_FEA/BRACS_1771_FEA_13.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/5_DCIS/BRACS_753_DCIS_20.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/4_ADH/BRACS_1922_ADH_8.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/0_N/BRACS_1231_N_56.png (already processed)\n",
            "[SKIP] BRACS/BRACS_RoI/latest_version/train/1_PB/BRACS_1774_PB_10.png (already processed)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-354807264.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;31m# wait for producers to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproducers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;31m# producers done: set stop event and wait for queues to drain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process Process-6:\n",
            "Process Process-8:\n",
            "Process Process-7:\n",
            "Traceback (most recent call last):\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}